{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "import struct\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import KDTree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === File Parsing Code ===\n",
    "def parse_ideal_line(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        version = struct.unpack(\"<i\", f.read(4))[0]\n",
    "        if version != 7:\n",
    "            raise ValueError(f\"Unsupported spline version: {version}\")\n",
    "\n",
    "        point_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "        lap_time = struct.unpack(\"<i\", f.read(4))[0]\n",
    "        sample_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "\n",
    "        # AiPoint: position (vec3), length, id\n",
    "        points = []\n",
    "        for _ in range(point_count):\n",
    "            x, y, z = struct.unpack(\"<fff\", f.read(12))\n",
    "            length = struct.unpack(\"<f\", f.read(4))[0]\n",
    "            point_id = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            points.append([x, y, z, length, point_id])\n",
    "\n",
    "        extra_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "        if extra_count != point_count:\n",
    "            raise ValueError(\"Mismatch between point count and extra data count.\")\n",
    "\n",
    "        # AiPointExtra: 18 floats = 72 bytes\n",
    "        extras = []\n",
    "        for _ in range(extra_count):\n",
    "            data = struct.unpack(\"<\" + \"f\" * 18, f.read(72))\n",
    "            extras.append(list(data))\n",
    "\n",
    "    columns = [\n",
    "        \"x\", \"y\", \"z\", \"length\", \"id\",\n",
    "        \"speed\", \"gas\", \"brake\", \"obsolete_lat_g\", \"radius\",\n",
    "        \"side_left\", \"side_right\", \"camber\", \"direction\",\n",
    "        \"normal_x\", \"normal_y\", \"normal_z\",\n",
    "        \"extra_length\",\n",
    "        \"forward_x\", \"forward_y\", \"forward_z\",\n",
    "        \"tag\", \"grade\"\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame([p + e for p, e in zip(points, extras)], columns=columns)\n",
    "    return df\n",
    "\n",
    "def parse_kn5_road_vertices(kn5_path, road_keywords=None):\n",
    "    \"\"\"\n",
    "    Extracts road-related mesh vertices from a .kn5 file.\n",
    "    Filters meshes by material or shader names using keywords.\n",
    "    \"\"\"\n",
    "    if road_keywords is None:\n",
    "        road_keywords = [\"road\", \"asphalt\", \"track\", \"surface\", \"pitlane\", \"curb\"]\n",
    "\n",
    "    with open(kn5_path, \"rb\") as f:\n",
    "        magic = f.read(6)\n",
    "        version = struct.unpack(\"<I\", f.read(4))[0]\n",
    "\n",
    "        if version > 5:\n",
    "            f.read(4)  # skip extra header if present\n",
    "\n",
    "        # TEXTURES\n",
    "        texture_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "        for _ in range(texture_count):\n",
    "            f.read(4)  # texture type\n",
    "            name_len = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            f.read(name_len)\n",
    "            tex_size = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            f.read(tex_size)\n",
    "\n",
    "        # MATERIALS\n",
    "        material_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "        materials = []\n",
    "        for _ in range(material_count):\n",
    "            name_len = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            name = f.read(name_len).decode(\"utf-8\").lower()\n",
    "            shader_len = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            shader = f.read(shader_len).decode(\"utf-8\").lower()\n",
    "            f.read(2)  # unknown short\n",
    "            if version > 4:\n",
    "                f.read(4)\n",
    "            prop_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            for _ in range(prop_count):\n",
    "                pname_len = struct.unpack(\"<i\", f.read(4))[0]\n",
    "                f.read(pname_len)\n",
    "                f.read(4)\n",
    "                f.read(36)\n",
    "            sample_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            for _ in range(sample_count):\n",
    "                sname_len = struct.unpack(\"<i\", f.read(4))[0]\n",
    "                f.read(sname_len)\n",
    "                f.read(4)\n",
    "                tname_len = struct.unpack(\"<i\", f.read(4))[0]\n",
    "                f.read(tname_len)\n",
    "            materials.append((name, shader))\n",
    "\n",
    "        # MESHES\n",
    "        mesh_vertices = []\n",
    "\n",
    "        def matches_road(mat_name, shader_name):\n",
    "            return any(k in mat_name for k in road_keywords) or any(k in shader_name for k in road_keywords)\n",
    "\n",
    "        def read_string():\n",
    "            strlen = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            return f.read(strlen).decode(\"utf-8\")\n",
    "\n",
    "        def read_vec3():\n",
    "            return struct.unpack(\"<3f\", f.read(12))\n",
    "\n",
    "        def read_node():\n",
    "            node_type = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            name = read_string()\n",
    "            child_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "            f.read(1)\n",
    "\n",
    "            if node_type == 1:  # Dummy node\n",
    "                f.read(64)\n",
    "            elif node_type in [2, 3]:  # Mesh or Animated Mesh\n",
    "                f.read(3)\n",
    "                vertex_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "                positions = []\n",
    "                for _ in range(vertex_count):\n",
    "                    pos = read_vec3()\n",
    "                    f.read(12 + 8 + 12)  # skip normals, UVs, tangents\n",
    "                    positions.append(pos)\n",
    "                idx_count = struct.unpack(\"<i\", f.read(4))[0]\n",
    "                f.read(idx_count * 2)  # indices\n",
    "                mat_id = struct.unpack(\"<i\", f.read(4))[0]\n",
    "                f.read(29 if node_type == 2 else 12)\n",
    "\n",
    "                if 0 <= mat_id < len(materials):\n",
    "                    mat_name, shader = materials[mat_id]\n",
    "                    if matches_road(mat_name, shader):\n",
    "                        mesh_vertices.extend(positions)\n",
    "\n",
    "            for _ in range(child_count):\n",
    "                read_node()\n",
    "\n",
    "        read_node()\n",
    "\n",
    "    return pd.DataFrame(mesh_vertices, columns=[\"x\", \"y\", \"z\"])\n",
    "\n",
    "def estimate_track_edges(kn5_path, spline_df, offset=6):\n",
    "    \"\"\"\n",
    "    Projects points perpendicular to the racing line, snaps to nearest road mesh vertex.\n",
    "    Returns left/right edge DataFrame with timestamp.\n",
    "    \"\"\"\n",
    "    mesh_df = parse_kn5_road_vertices(kn5_path)\n",
    "    mesh_tree = KDTree(mesh_df[[\"x\", \"z\"]].values)\n",
    "\n",
    "    left_pts = []\n",
    "    right_pts = []\n",
    "\n",
    "    for i in range(1, len(spline_df) - 1):\n",
    "        x1, y1 = spline_df.iloc[i - 1][[\"x\", \"z\"]]\n",
    "        x2, y2 = spline_df.iloc[i + 1][[\"x\", \"z\"]]\n",
    "        dx, dy = x2 - x1, y2 - y1\n",
    "        norm = np.hypot(dx, dy)\n",
    "        if norm == 0:\n",
    "            continue\n",
    "\n",
    "        perp = np.array([-dy, dx]) / norm\n",
    "        cx, cy = spline_df.iloc[i][[\"x\", \"z\"]]\n",
    "        left_query = np.array([cx, cy]) + perp * offset\n",
    "        right_query = np.array([cx, cy]) - perp * offset\n",
    "\n",
    "        _, left_idx = mesh_tree.query(left_query)\n",
    "        _, right_idx = mesh_tree.query(right_query)\n",
    "\n",
    "        left_pts.append(mesh_df.iloc[left_idx].values)\n",
    "        right_pts.append(mesh_df.iloc[right_idx].values)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"timestamp\": np.arange(len(left_pts)),\n",
    "        \"left_x\": [pt[0] for pt in left_pts],\n",
    "        \"left_y\": [pt[1] for pt in left_pts],\n",
    "        \"left_z\": [pt[2] for pt in left_pts],\n",
    "        \"right_x\": [pt[0] for pt in right_pts],\n",
    "        \"right_y\": [pt[1] for pt in right_pts],\n",
    "        \"right_z\": [pt[2] for pt in right_pts],\n",
    "    })\n",
    "\n",
    "# === Pipeline Helpers ===\n",
    "def find_kn5_file(track_path, track_name):\n",
    "    \"\"\"Find the .kn5 file that matches the track name inside the track folder.\"\"\"\n",
    "    expected_kn5 = f\"{track_name}.kn5\"\n",
    "    kn5_path = os.path.join(track_path, expected_kn5)\n",
    "    return kn5_path if os.path.isfile(kn5_path) else None\n",
    "\n",
    "def find_ai_files(track_path):\n",
    "    \"\"\"Finds all valid layout pairs: (fast_lane.ai, ideal_line.ai)\"\"\"\n",
    "\n",
    "    layouts = []\n",
    "\n",
    "    # Case 1: single-layout in root (ai/ and data/ inside track root)\n",
    "    root_fast = os.path.join(track_path, \"ai\", \"fast_lane.ai\")\n",
    "    root_ideal = os.path.join(track_path, \"data\", \"ideal_line.ai\")\n",
    "    if os.path.isfile(root_fast) and os.path.isfile(root_ideal):\n",
    "        layouts.append((root_fast, root_ideal))\n",
    "\n",
    "    # Case 2: multiple layouts in subfolders\n",
    "    for sub in os.listdir(track_path):\n",
    "        layout_path = os.path.join(track_path, sub)\n",
    "        if not os.path.isdir(layout_path):\n",
    "            continue\n",
    "\n",
    "        fast_path = os.path.join(layout_path, \"ai\", \"fast_lane.ai\")\n",
    "        ideal_path = os.path.join(layout_path, \"data\", \"ideal_line.ai\")\n",
    "\n",
    "        if os.path.isfile(fast_path) and os.path.isfile(ideal_path):\n",
    "            layouts.append((fast_path, ideal_path))\n",
    "\n",
    "    return layouts\n",
    "\n",
    "# === Per-track processor ===\n",
    "def process_track(track_name, tracks_root, output_root):\n",
    "    track_path = os.path.join(tracks_root, track_name)\n",
    "    if not os.path.isdir(track_path):\n",
    "        return\n",
    "\n",
    "    kn5_path = find_kn5_file(track_path, track_name)\n",
    "    if not kn5_path:\n",
    "        print(f\"No KN5 file for {track_name}, skipping...\")\n",
    "        return\n",
    "\n",
    "    layouts = find_ai_files(track_path)\n",
    "    if not layouts:\n",
    "        print(f\"No valid layouts found for {track_name}, skipping...\")\n",
    "        return\n",
    "\n",
    "    track_output_dir = os.path.join(output_root, track_name)\n",
    "    os.makedirs(track_output_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"\\nProcessing {track_name} with {len(layouts)} layout(s)...\")\n",
    "\n",
    "    for i, (fast_path, ideal_path) in enumerate(layouts):\n",
    "        layout_name = f\"layout{i+1}\"\n",
    "        layout_dir = os.path.join(track_output_dir, layout_name)\n",
    "        os.makedirs(layout_dir, exist_ok=True)\n",
    "\n",
    "        try:\n",
    "            centerline_df = parse_ideal_line(fast_path)\n",
    "            edges_df = estimate_track_edges(kn5_path, centerline_df, offset=6.0)\n",
    "\n",
    "            ideal_df = parse_ideal_line(ideal_path)\n",
    "\n",
    "            ideal_df.to_csv(os.path.join(layout_dir, \"ideal_line.csv\"), index=False)\n",
    "            edges_df.to_csv(os.path.join(layout_dir, \"track_edges.csv\"), index=False)\n",
    "\n",
    "            print(f\"Saved {layout_name}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {layout_name}: {e}\")\n",
    "\n",
    "    print(f\"Finished {track_name}.\")\n",
    "\n",
    "# === All Tracks Entry Point ===\n",
    "def process_all_tracks(tracks_root, output_root):\n",
    "    for track_name in os.listdir(tracks_root):\n",
    "        process_track(track_name, tracks_root, output_root)\n",
    "    print(\"Finished all tracks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing imola with 1 layout(s)...\n",
      "Failed to process layout1: Unsupported spline version: 2\n",
      "Finished imola.\n",
      "\n",
      "Processing ks_barcelona with 2 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Finished ks_barcelona.\n",
      "\n",
      "Processing ks_black_cat_county with 3 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Saved layout3.\n",
      "Finished ks_black_cat_county.\n",
      "\n",
      "Processing ks_brands_hatch with 2 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Finished ks_brands_hatch.\n",
      "No valid layouts found for ks_drag, skipping...\n",
      "\n",
      "Processing ks_highlands with 4 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Saved layout3.\n",
      "Saved layout4.\n",
      "Finished ks_highlands.\n",
      "\n",
      "Processing ks_laguna_seca with 1 layout(s)...\n",
      "Saved layout1.\n",
      "Finished ks_laguna_seca.\n",
      "\n",
      "Processing ks_monza66 with 3 layout(s)...\n",
      "Failed to process layout1: single positional indexer is out-of-bounds\n",
      "Failed to process layout2: single positional indexer is out-of-bounds\n",
      "Failed to process layout3: single positional indexer is out-of-bounds\n",
      "Finished ks_monza66.\n",
      "\n",
      "Processing ks_nordschleife with 4 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Saved layout3.\n",
      "Saved layout4.\n",
      "Finished ks_nordschleife.\n",
      "\n",
      "Processing ks_nurburgring with 4 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Saved layout3.\n",
      "Saved layout4.\n",
      "Finished ks_nurburgring.\n",
      "\n",
      "Processing ks_red_bull_ring with 2 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Finished ks_red_bull_ring.\n",
      "\n",
      "Processing ks_silverstone with 3 layout(s)...\n",
      "Failed to process layout1: Unsupported spline version: 2\n",
      "Saved layout2.\n",
      "Saved layout3.\n",
      "Finished ks_silverstone.\n",
      "\n",
      "Processing ks_silverstone1967 with 1 layout(s)...\n",
      "Saved layout1.\n",
      "Finished ks_silverstone1967.\n",
      "\n",
      "Processing ks_vallelunga with 3 layout(s)...\n",
      "Saved layout1.\n",
      "Saved layout2.\n",
      "Failed to process layout3: Unsupported spline version: 6\n",
      "Finished ks_vallelunga.\n",
      "\n",
      "Processing ks_zandvoort with 1 layout(s)...\n",
      "Saved layout1.\n",
      "Finished ks_zandvoort.\n",
      "\n",
      "Processing magione with 1 layout(s)...\n",
      "Failed to process layout1: Unsupported spline version: 2\n",
      "Finished magione.\n",
      "\n",
      "Processing monza with 1 layout(s)...\n",
      "Saved layout1.\n",
      "Finished monza.\n",
      "\n",
      "Processing mugello with 1 layout(s)...\n",
      "Failed to process layout1: Unsupported spline version: 3\n",
      "Finished mugello.\n",
      "\n",
      "Processing spa with 1 layout(s)...\n",
      "Saved layout1.\n",
      "Finished spa.\n",
      "No valid layouts found for trento-bondone, skipping...\n"
     ]
    }
   ],
   "source": [
    "# Dataset Creation Pipeline.\n",
    "TRACKS_ROOT = \"../data/assetto_corsa_tracks\"\n",
    "OUTPUT_ROOT = \"../data/extracted_track_data\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_tracks(TRACKS_ROOT, OUTPUT_ROOT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
