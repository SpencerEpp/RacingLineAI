{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1924579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.serialization\n",
    "torch.serialization.add_safe_globals([MinMaxScaler])\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79017fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing config\n",
    "config = {\n",
    "    \"model_type\": \"lstm\", # Options: \"lstm\", \"cnn\", \"tcn\", \"transformer\" \n",
    "    \"seed\": 42,\n",
    "    \"input_size\": 6,\n",
    "    \"output_size\": 3,\n",
    "    \"train_split\": 0.8,\n",
    "    \"num_epochs\": 50,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 4,\n",
    "    \"dropout\": 0.1,\n",
    "    \"seq_len\": 150,\n",
    "    \"patience\": 10,\n",
    "    \"bidirectional\": False,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"train_data_path\": \"./data/testing_layouts/\", #\"./data/extracted_track_data/\",\n",
    "    \"test_data_path\": \"./data/testing_layouts/\",\n",
    "    \"model_save_path\": \"./models/t_racing_line_lstm.pt\",\n",
    "    \"input_cols\": [\"left_x\",\"left_y\",\"left_z\",\"right_x\",\"right_y\",\"right_z\"],\n",
    "    \"output_cols\": [\"x\",\"y\",\"z\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c110d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model with Attention ===\n",
    "class RacingLineLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, config, scaler_x=None, scaler_y=None):\n",
    "        super().__init__()\n",
    "        self.bidirectional = config[\"bidirectional\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_directions = 2 if self.bidirectional else 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config[\"input_size\"],\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "        self.attn = nn.Linear(self.num_directions * self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        self.fc = nn.Linear(self.num_directions * self.hidden_size, config[\"output_size\"])\n",
    "\n",
    "        # Optional scalers for external inference use\n",
    "        self.scaler_x = scaler_x\n",
    "        self.scaler_y = scaler_y\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x) # x: (batch, seq_len, input_size)\n",
    "        attn_scores = self.attn(lstm_out)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
    "        context = self.dropout(context)\n",
    "        return self.fc(context)\n",
    "\n",
    "    def get_attention_weights(self, x):\n",
    "        \"\"\"Optional: for visualization/debugging\"\"\"\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attn_scores = self.attn(lstm_out)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        return attn_weights.squeeze(-1)  # (batch, seq_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1c159f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other basic models to try (needs testing)\n",
    "\n",
    "#=======================================================================================\n",
    "# 1D CNN\n",
    "class RacingLineCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(config[\"input_size\"], 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, config[\"output_size\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # CNN expects [Batch size, Channels (features), Time (sequence length)]\n",
    "        return self.net(x)\n",
    "\n",
    "#=======================================================================================\n",
    "# Temporal Convolutional Network\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size]\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, dilation, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size, stride, padding, dilation=dilation),\n",
    "            Chomp1d(padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(out_ch, out_ch, kernel_size, stride, padding, dilation=dilation),\n",
    "            Chomp1d(padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res\n",
    "\n",
    "class RacingLineTCN(nn.Module):\n",
    "    def __init__(self, config, levels=2, kernel_size=2):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_ch = config[\"input_size\"]\n",
    "        for i in range(levels):\n",
    "            out_ch = 64\n",
    "            dilation = 2 ** i\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            layers.append(TemporalBlock(in_ch, out_ch, kernel_size, 1, dilation, padding, config[\"dropout\"]))\n",
    "            in_ch = out_ch\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(in_ch, config[\"output_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.network(x)\n",
    "        out = out[:, :, -1]\n",
    "        return self.linear(out)\n",
    "\n",
    "#=======================================================================================\n",
    "# Transformer Model\n",
    "class LearnablePositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, max_len, d_model))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embedding[:, :x.size(1), :]\n",
    "\n",
    "class RacingLineTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(config[\"input_size\"], config[\"hidden_size\"])\n",
    "        self.pos_encoding = LearnablePositionalEncoding(max_len=config[\"seq_len\"], d_model=config[\"hidden_size\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"hidden_size\"],\n",
    "            nhead=4,\n",
    "            dropout=config[\"dropout\"],\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=config[\"num_layers\"])\n",
    "        self.fc = nn.Linear(config[\"hidden_size\"], config[\"output_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoding(x) \n",
    "        x = self.transformer(x)\n",
    "        return self.fc(x)\n",
    "    \n",
    "#=======================================================================================\n",
    "# GNN/GCN (an idea to try if we desire)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2fb4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config, scaler_x=None, scaler_y=None):\n",
    "    match config[\"model_type\"]:\n",
    "        case \"lstm\":\n",
    "            return RacingLineLSTMWithAttention(config, scaler_x=scaler_x, scaler_y=scaler_y)\n",
    "        case \"cnn\":\n",
    "            return RacingLineCNN(config)\n",
    "        case \"tcn\":\n",
    "            return RacingLineTCN(config)\n",
    "        case \"transformer\":\n",
    "            return RacingLineTransformer(config)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown model type: {config['model_type']}\")\n",
    "\n",
    "def load_model(path, config):\n",
    "    checkpoint = torch.load(path, map_location=config[\"device\"], weights_only=False)\n",
    "    cfg = checkpoint[\"config\"]\n",
    "    model = get_model(cfg)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(cfg[\"device\"])\n",
    "    scaler_x = checkpoint[\"scaler_x\"]\n",
    "    scaler_y = checkpoint[\"scaler_y\"]\n",
    "    return model, scaler_x, scaler_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbba944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and scalers...\n",
      "Loading unseen layouts from: ./data/testing_layouts\n",
      "Found 1 layout files.\n",
      "\n",
      "[1/1] Predicting layout: ks_barcelona_layout_gp_Processed_Data.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130faf2c67fb46a38326e7f2fb61ae9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "[1/1]:   0%|          | 0/2779 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMean X/Z spatial error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmean_spatial_error\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mm, Max: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_spatial_error\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mm\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     91\u001b[39m \u001b[38;5;66;03m# === Run it ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data/testing_layouts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./models/t_racing_line_lstm.pt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mrun_inference\u001b[39m\u001b[34m(config, data_folder, model_path)\u001b[39m\n\u001b[32m     62\u001b[39m         idx = i + j\n\u001b[32m     63\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m idx < n:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m             preds_real[idx] += \u001b[43mpred_real\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     65\u001b[39m             count_map[idx] += \u001b[32m1\u001b[39m\n\u001b[32m     67\u001b[39m count_map[count_map == \u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m\n",
      "\u001b[31mIndexError\u001b[39m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "def print_feature_accuracy(preds, trues, scaler_y, feature_names):\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "\n",
    "    print(f\"\\nPer-Feature Accuracy (%):\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, name in enumerate(feature_names):\n",
    "        range_train = scaler_y.scale_[i]\n",
    "        range_test = trues[:, i].max() - trues[:, i].min()\n",
    "\n",
    "        if range_test == 0:\n",
    "            print(f\"{name:>16}: N/A (zero test range)\")\n",
    "            continue\n",
    "\n",
    "        mean_error = np.mean(np.abs(preds[:, i] - trues[:, i]))\n",
    "        acc_train = (1 - (mean_error / range_train)) * 100\n",
    "        acc_test = (1 - (mean_error / range_test)) * 100\n",
    "\n",
    "        acc_train = max(0.0, min(100.0, acc_train))\n",
    "        acc_test = max(0.0, min(100.0, acc_test))\n",
    "\n",
    "        print(f\"{name:>16}: {acc_test:6.2f}% (layout-based)   {acc_train:6.2f}% (train-scale)\")\n",
    "\n",
    "# === Inference for Sequence-to-Sequence on Non-Circular Tracks ===\n",
    "def run_inference(config, data_folder, model_path):\n",
    "    print(\"Loading model and scalers...\")\n",
    "    model, scaler_x, scaler_y = load_model(model_path, config)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Loading unseen layouts from:\", data_folder)\n",
    "    layout_files = sorted(glob(os.path.join(data_folder, \"*.csv\")))\n",
    "    total_layouts = len(layout_files)\n",
    "    print(f\"Found {total_layouts} layout files.\\n\")\n",
    "\n",
    "    for layout_index, layout_path in enumerate(layout_files):\n",
    "        layout_name = os.path.basename(layout_path)\n",
    "        print(f\"[{layout_index + 1}/{total_layouts}] Predicting layout: {layout_name}\")\n",
    "\n",
    "        df = pd.read_csv(layout_path)\n",
    "        X = df[config[\"input_cols\"]].values\n",
    "        Y = df[config[\"output_cols\"]].values\n",
    "        X_scaled = scaler_x.transform(X)\n",
    "        n = len(X_scaled)\n",
    "\n",
    "        trues_real = Y.copy()\n",
    "        preds_real = np.zeros_like(Y)\n",
    "        count_map = np.zeros((n, 1))\n",
    "\n",
    "        for i in tqdm(range(0, n - config[\"seq_len\"]+1), desc=f\"[{layout_index + 1}/{total_layouts}]\"):\n",
    "            seq = X_scaled[i:i + config[\"seq_len\"]] \n",
    "            X_tensor = torch.tensor(seq.reshape(1, config[\"seq_len\"], -1), dtype=torch.float32).to(config[\"device\"])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_scaled = model(X_tensor).cpu().squeeze(0).numpy()  \n",
    "                pred_real = scaler_y.inverse_transform(pred_scaled.reshape(1, -1))[0] \n",
    "                # print(\"pred_real shape:\", pred_real.shape)\n",
    "                # print(\"pred_real[:5]:\", pred_real[:5])\n",
    "                # print(\"pred_scaled shape:\", pred_scaled.shape)\n",
    "                # print(\"pred_scaled[:5]:\", pred_scaled[:5])\n",
    "\n",
    "            for j in range(config[\"seq_len\"]):\n",
    "                idx = i + j\n",
    "                if idx < n:\n",
    "                    preds_real[idx] += pred_real[j]\n",
    "                    count_map[idx] += 1\n",
    "\n",
    "        count_map[count_map == 0] = 1\n",
    "        preds_real /= count_map\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(trues_real[:, 0], trues_real[:, 2], label=\"True\", linewidth=2)\n",
    "        plt.plot(preds_real[:, 0], preds_real[:, 2], label=\"Predicted\", linewidth=2, linestyle=\"--\")\n",
    "        plt.title(f\"X vs Z: {layout_name}\")\n",
    "        plt.xlabel(\"X Coordinate\")\n",
    "        plt.ylabel(\"Z Coordinate\")\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Accuracy\n",
    "        print_feature_accuracy(preds_real, trues_real, scaler_y, config[\"output_cols\"])\n",
    "\n",
    "        # Spatial Error\n",
    "        spatial_errors = np.linalg.norm(preds_real[:, [0, 2]] - trues_real[:, [0, 2]], axis=1)\n",
    "        mean_spatial_error = np.mean(spatial_errors)\n",
    "        max_spatial_error = np.max(spatial_errors)\n",
    "        print(f\"Mean X/Z spatial error: {mean_spatial_error:.2f}m, Max: {max_spatial_error:.2f}m\\n\")\n",
    "\n",
    "# === Run it ===\n",
    "run_inference(config, data_folder=\"./data/testing_layouts\", model_path=\"./models/t_racing_line_lstm.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
