{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Pipeline for Racing Line Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check to ensure model will run on GPU\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.serialization\n",
    "torch.serialization.add_safe_globals([MinMaxScaler])\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "\n",
    "# First Run Config\n",
    "# config = {\n",
    "#     \"seed\": 42,\n",
    "#     \"input_size\": 6,\n",
    "#     \"output_size\": 23,\n",
    "#     \"train_split\": 0.8,\n",
    "#     \"num_epochs\": 50,\n",
    "#     \"learning_rate\": 0.001,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"hidden_size\": 128,\n",
    "#     \"num_layers\": 2,\n",
    "#     \"dropout\": 0.2,\n",
    "#     \"seq_len\": 50,\n",
    "#     \"patience\": 10,\n",
    "#     \"pin_memory\": True,\n",
    "#     \"bidirectional\": True,\n",
    "#     \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "#     \"train_data_path\": \"./data/extracted_track_data/\",\n",
    "#     \"model_save_path\": \"./models/racing_line_lstm.pt\",\n",
    "#     \"input_cols\": [\"left_x\",\"left_y\",\"left_z\",\"right_x\",\"right_y\",\"right_z\"],\n",
    "#     \"output_cols\": [\"x\",\"y\",\"z\",\"length\",\"id\",\"speed\",\"gas\",\"brake\",\"obsolete_lat_g\",\"radius\",\"side_left\",\"side_right\",\"camber\",\n",
    "#                     \"direction\",\"normal_x\",\"normal_y\",\"normal_z\",\"extra_length\",\"forward_x\",\"forward_y\",\"forward_z\",\"tag\",\"grade\"]\n",
    "# }\n",
    "\n",
    "# Long Run Config\n",
    "# config = {\n",
    "#     \"seed\": 42,\n",
    "#     \"input_size\": 6,\n",
    "#     \"output_size\": 23,\n",
    "#     \"train_split\": 0.8,\n",
    "#     \"num_epochs\": 200,\n",
    "#     \"learning_rate\": 0.0005,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"hidden_size\": 512,\n",
    "#     \"num_layers\": 4,\n",
    "#     \"dropout\": 0.1,\n",
    "#     \"seq_len\": 50,\n",
    "#     \"patience\": 25,\n",
    "#     \"pin_memory\": True,\n",
    "#     \"bidirectional\": True,\n",
    "#     \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "#     \"train_data_path\": \"./data/extracted_track_data/\",\n",
    "#     \"model_save_path\": \"./models/seven_feat_racing_line_lstm.pt\",\n",
    "#     \"input_cols\": [\"left_x\",\"left_y\",\"left_z\",\"right_x\",\"right_y\",\"right_z\"],\n",
    "#     \"output_cols\": [\"x\",\"y\",\"z\",\"length\",\"id\",\"speed\",\"gas\",\"brake\",\"obsolete_lat_g\",\"radius\",\"side_left\",\"side_right\",\"camber\",\n",
    "#                     \"direction\",\"normal_x\",\"normal_y\",\"normal_z\",\"extra_length\",\"forward_x\",\"forward_y\",\"forward_z\",\"tag\",\"grade\"]\n",
    "# }\n",
    "\n",
    "# Less target features still big model but less epochs\n",
    "# config = {\n",
    "#     \"seed\": 42,\n",
    "#     \"input_size\": 6,\n",
    "#     \"output_size\": 7,\n",
    "#     \"train_split\": 0.8,\n",
    "#     \"num_epochs\": 50,\n",
    "#     \"learning_rate\": 0.0005,\n",
    "#     \"batch_size\": 64,\n",
    "#     \"hidden_size\": 512,\n",
    "#     \"num_layers\": 4,\n",
    "#     \"dropout\": 0.1,\n",
    "#     \"seq_len\": 50,\n",
    "#     \"patience\": 25,\n",
    "#     \"pin_memory\": True,\n",
    "#     \"bidirectional\": True,\n",
    "#     \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "#     \"train_data_path\": \"./data/extracted_track_data/\",\n",
    "#     \"model_save_path\": \"./models/seven_feat_racing_line_lstm.pt\",\n",
    "#     \"input_cols\": [\"left_x\",\"left_y\",\"left_z\",\"right_x\",\"right_y\",\"right_z\"],\n",
    "#     \"output_cols\": [\"x\",\"y\",\"z\",\"gas\",\"brake\",\"side_left\",\"side_right\"]\n",
    "# }\n",
    "\n",
    "#Testing config\n",
    "config = {\n",
    "    \"model_type\": \"lstm\", # Options: \"lstm\", \"cnn\", \"tcn\", \"transformer\" \n",
    "    \"seed\": 42,\n",
    "    \"input_size\": 6,\n",
    "    \"output_size\": 3,\n",
    "    \"train_split\": 0.8,\n",
    "    \"num_epochs\": 50,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 2,\n",
    "    \"dropout\": 0.2,\n",
    "    \"seq_len\": 150,\n",
    "    \"patience\": 10,\n",
    "    \"pin_memory\": True,\n",
    "    \"bidirectional\": False,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"train_data_path\": \"./data/extracted_track_data/\",\n",
    "    \"test_data_path\": \"./data/testing_layouts/\",\n",
    "    \"model_save_path\": \"./models/testing_racing_line_lstm.pt\",\n",
    "    \"input_cols\": [\"left_x\",\"left_y\",\"left_z\",\"right_x\",\"right_y\",\"right_z\"],\n",
    "    \"output_cols\": [\"x\",\"y\",\"z\"]\n",
    "}\n",
    "\n",
    "random.seed(config[\"seed\"])\n",
    "np.random.seed(config[\"seed\"])\n",
    "torch.manual_seed(config[\"seed\"])\n",
    "torch.cuda.manual_seed(config[\"seed\"])\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Dataset ===\n",
    "class RacingLineDataset(Dataset):\n",
    "    def __init__(self, train_data_path, test_data_path, seq_len):\n",
    "        self.inputs, self.targets = [], []\n",
    "        self.seq_len = seq_len\n",
    "        self.scaler_x = MinMaxScaler()\n",
    "        self.scaler_y = MinMaxScaler()\n",
    "        all_X, all_Y = [], []\n",
    "        train_files = sorted(glob(os.path.join(train_data_path, \"*.csv\")))\n",
    "        test_files = sorted(glob(os.path.join(test_data_path, \"*.csv\")))\n",
    "\n",
    "        # === First pass: Collect data for global fitting ===\n",
    "        for file in train_files:\n",
    "            df = pd.read_csv(file)\n",
    "            X = df[config[\"input_cols\"]].values\n",
    "            Y = df[config[\"output_cols\"]].values\n",
    "            all_X.append(X)\n",
    "            all_Y.append(Y)\n",
    "        for file in test_files:\n",
    "            df = pd.read_csv(file)\n",
    "            X = df[config[\"input_cols\"]].values\n",
    "            Y = df[config[\"output_cols\"]].values\n",
    "            all_X.append(X)\n",
    "            all_Y.append(Y)\n",
    "        all_X = np.vstack(all_X)\n",
    "        all_Y = np.vstack(all_Y)\n",
    "        self.scaler_x.fit(all_X)\n",
    "        self.scaler_y.fit(all_Y)\n",
    "\n",
    "        # === Second pass: Normalize and extract sequences ===\n",
    "        for file in train_files:\n",
    "            df = pd.read_csv(file)\n",
    "            X = self.scaler_x.transform(df[config[\"input_cols\"]].values)\n",
    "            Y = self.scaler_y.transform(df[config[\"output_cols\"]].values)\n",
    "\n",
    "            for i in range((len(X) - seq_len) + 1):\n",
    "                self.inputs.append(X[i:i+seq_len])\n",
    "                self.targets.append(Y[i+seq_len-1])\n",
    "\n",
    "        # Convert to tensors\n",
    "        self.inputs = torch.tensor(np.array(self.inputs), dtype=torch.float32)\n",
    "        self.targets = torch.tensor(np.array(self.targets), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx], self.pred_indices[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model with Attention ===\n",
    "class RacingLineLSTMWithAttention(nn.Module):\n",
    "    def __init__(self, config, scaler_x=None, scaler_y=None):\n",
    "        super().__init__()\n",
    "        self.bidirectional = config[\"bidirectional\"]\n",
    "        self.hidden_size = config[\"hidden_size\"]\n",
    "        self.num_directions = 2 if self.bidirectional else 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=config[\"input_size\"],\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=config[\"num_layers\"],\n",
    "            dropout=config[\"dropout\"],\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional\n",
    "        )\n",
    "\n",
    "        self.attn = nn.Linear(self.num_directions * self.hidden_size, 1)\n",
    "        self.dropout = nn.Dropout(config[\"dropout\"])\n",
    "        self.fc = nn.Linear(self.num_directions * self.hidden_size, config[\"output_size\"])\n",
    "\n",
    "        # Optional scalers for external inference use\n",
    "        self.scaler_x = scaler_x\n",
    "        self.scaler_y = scaler_y\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x) # x: (batch, seq_len, input_size)\n",
    "        attn_scores = self.attn(lstm_out)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        context = torch.sum(attn_weights * lstm_out, dim=1)\n",
    "        context = self.dropout(context)\n",
    "        return self.fc(context)\n",
    "\n",
    "    def get_attention_weights(self, x):\n",
    "        \"\"\"Optional: for visualization/debugging\"\"\"\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attn_scores = self.attn(lstm_out)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=1)\n",
    "        return attn_weights.squeeze(-1)  # (batch, seq_len)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other basic models to try (needs testing)\n",
    "\n",
    "#=======================================================================================\n",
    "# 1D CNN\n",
    "class RacingLineCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(config[\"input_size\"], 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, config[\"output_size\"])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # CNN expects [Batch size, Channels (features), Time (sequence length)]\n",
    "        return self.net(x)\n",
    "\n",
    "#=======================================================================================\n",
    "# Temporal Convolutional Network\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super().__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size]\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, dilation, padding, dropout):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv1d(in_ch, out_ch, kernel_size, stride, padding, dilation=dilation),\n",
    "            Chomp1d(padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv1d(out_ch, out_ch, kernel_size, stride, padding, dilation=dilation),\n",
    "            Chomp1d(padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return out + res\n",
    "\n",
    "class RacingLineTCN(nn.Module):\n",
    "    def __init__(self, config, levels=3, kernel_size=3):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_ch = config[\"input_size\"]\n",
    "        for i in range(levels):\n",
    "            out_ch = 64 * (2 ** i)\n",
    "            dilation = 2 ** i\n",
    "            padding = (kernel_size - 1) * dilation\n",
    "            layers.append(TemporalBlock(in_ch, out_ch, kernel_size, 1, dilation, padding, config[\"dropout\"]))\n",
    "            in_ch = out_ch\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        self.linear = nn.Linear(in_ch, config[\"output_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out = self.network(x)\n",
    "        out = out[:, :, -1]\n",
    "        return self.linear(out)\n",
    "\n",
    "#=======================================================================================\n",
    "# Transformer Model\n",
    "class RacingLineTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Linear(config[\"input_size\"], config[\"hidden_size\"])\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=config[\"hidden_size\"],\n",
    "            nhead=4,\n",
    "            dropout=config[\"dropout\"],\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=config[\"num_layers\"])\n",
    "        self.fc = nn.Linear(config[\"hidden_size\"], config[\"output_size\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer(x)\n",
    "        return self.fc(x[:, -1])\n",
    "    \n",
    "#=======================================================================================\n",
    "# GNN/GCN (an idea to try if we desire)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model Selector ===\n",
    "def get_model(config, scaler_x=None, scaler_y=None):\n",
    "    match config[\"model_type\"]:\n",
    "        case \"lstm\":\n",
    "            return RacingLineLSTMWithAttention(config, scaler_x=scaler_x, scaler_y=scaler_y)\n",
    "        case \"cnn\":\n",
    "            return RacingLineCNN(config)\n",
    "        case \"tcn\":\n",
    "            return RacingLineTCN(config)\n",
    "        case \"transformer\":\n",
    "            return RacingLineTransformer(config)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown model type: {config['model_type']}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluation/Loss Functions ===\n",
    "def hybrid_loss(preds, targets, alpha=0.9):\n",
    "    euclidean = torch.norm(preds - targets, dim=1).mean()\n",
    "    cosine = 1 - F.cosine_similarity(preds, targets, dim=1).mean()\n",
    "    return alpha * euclidean + (1 - alpha) * cosine\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, config):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, Y_batch, _ in dataloader:\n",
    "            X_batch, Y_batch = X_batch.to(config[\"device\"]), Y_batch.to(config[\"device\"])\n",
    "            if config[\"model_type\"] in [\"cnn\", \"tcn\"]: X_batch = X_batch.permute(0,2,1)\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, Y_batch)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save and Load Model (with architecture) ===\n",
    "def save_model(model, config, scaler_x, scaler_y):\n",
    "    torch.save({\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"config\": config,\n",
    "        \"scaler_x\": scaler_x,\n",
    "        \"scaler_y\": scaler_y,\n",
    "    }, config[\"model_save_path\"])\n",
    "\n",
    "# def load_model(path):\n",
    "#     checkpoint = torch.load(path, map_location=config[\"device\"], weights_only=False)\n",
    "#     cfg = checkpoint[\"config\"]\n",
    "#     model = RacingLineLSTMWithAttention(cfg[\"input_size\"], cfg[\"hidden_size\"],\n",
    "#                                         cfg[\"output_size\"], cfg[\"num_layers\"],\n",
    "#                                         cfg[\"dropout\"], cfg[\"bidirectional\"])\n",
    "#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "#     model.to(cfg[\"device\"])\n",
    "#     return model, checkpoint[\"scaler_x\"], checkpoint[\"scaler_y\"]\n",
    "\n",
    "def load_model(path):\n",
    "    checkpoint = torch.load(path, map_location=config[\"device\"], weights_only=False)\n",
    "    cfg = checkpoint[\"config\"]\n",
    "    model = get_model(cfg)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(cfg[\"device\"])\n",
    "    scaler_x = checkpoint[\"scaler_x\"]\n",
    "    scaler_y = checkpoint[\"scaler_y\"]\n",
    "    return model, scaler_x, scaler_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Training Function (with tqdm and validation) ===\n",
    "def train_model(model, train_loader, val_loader, config, scaler_x, scaler_y):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"learning_rate\"])\n",
    "    criterion = hybrid_loss #nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    early_stopping_patience = config[\"patience\"]\n",
    "    epochs_without_improvement = 0\n",
    "    best_epoch = 0\n",
    "\n",
    "    obar = tqdm(range(config[\"num_epochs\"]), desc=\"Epochs\")\n",
    "    for epoch in obar:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config['num_epochs']}\", leave=False)\n",
    "        for X_batch, Y_batch, _ in pbar:\n",
    "            X_batch, Y_batch = X_batch.to(config[\"device\"]), Y_batch.to(config[\"device\"])\n",
    "            if config[\"model_type\"] in [\"cnn\", \"tcn\"]: X_batch = X_batch.permute(0,2,1)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch)\n",
    "            loss = criterion(preds, Y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            pbar.set_postfix({\"Loss\": running_loss / (pbar.n + 1)})\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        val_loss = evaluate_model(model, val_loader, criterion, config)\n",
    "        val_losses.append(val_loss)\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            save_model(model, config, scaler_x, scaler_y)\n",
    "            best_epoch = epoch+1\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        obar.set_postfix({\"Train Loss\": running_loss/len(train_loader), \"Val Loss\": val_loss, \"Lr\": scheduler.get_last_lr()[0], \"best_epoch\": best_epoch})\n",
    "\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Full Pipeline ===\n",
    "def run_pipeline(train_data_path=config[\"train_data_path\"], test_data_path=config[\"test_data_path\"]):\n",
    "    print(\"Preparing dataset...\")\n",
    "    full_dataset = RacingLineDataset(\n",
    "        train_data_path,\n",
    "        test_data_path,\n",
    "        config[\"seq_len\"],\n",
    "    )\n",
    "    scaler_x = full_dataset.scaler_x\n",
    "    scaler_y = full_dataset.scaler_y\n",
    "    print(\"Total sequences loaded:\", len(full_dataset))\n",
    "\n",
    "    # === 80/20 train/val split with reproducibility ===\n",
    "    train_len = int(len(full_dataset) * config[\"train_split\"])\n",
    "    val_len = len(full_dataset) - train_len\n",
    "    train_ds, val_ds = random_split(\n",
    "        full_dataset,\n",
    "        [train_len, val_len],\n",
    "        generator=torch.Generator().manual_seed(config[\"seed\"])\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=config[\"batch_size\"], shuffle=False, pin_memory=config[\"pin_memory\"])\n",
    "    val_loader = DataLoader(val_ds, batch_size=config[\"batch_size\"], shuffle=False, pin_memory=config[\"pin_memory\"])\n",
    "\n",
    "    print(f\"Initializing model: {config[\"model_type\"]}...\")\n",
    "    model = get_model(config=config, scaler_x=scaler_x, scaler_y=scaler_y).to(config[\"device\"])\n",
    "\n",
    "    print(\"Training started...\")\n",
    "    train_losses, val_losses = train_model(model, train_loader, val_loader, config, scaler_x, scaler_y)\n",
    "    print(f\"Training complete. Model saved to {config['model_save_path']}\")\n",
    "\n",
    "    # === Plot learning curve ===\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label=\"Train Loss\")\n",
    "    plt.plot(val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train Model ===\n",
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Inference on Testing Track Layouts (from coordinates only, doesnt take image for inference) ===\n",
    "def print_feature_accuracy(preds, trues, scaler_y, feature_names):\n",
    "    preds = np.array(preds)\n",
    "    trues = np.array(trues)\n",
    "\n",
    "    print(f\"\\nPer-Feature Accuracy (%):\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, name in enumerate(feature_names):\n",
    "        range_train = scaler_y.scale_[i]\n",
    "        range_test = trues[:, i].max() - trues[:, i].min()\n",
    "\n",
    "        if range_test == 0:\n",
    "            print(f\"{name:>16}: N/A (zero test range)\")\n",
    "            continue\n",
    "\n",
    "        mean_error = np.mean(np.abs(preds[:, i] - trues[:, i]))\n",
    "        acc_train = (1 - (mean_error / range_train)) * 100\n",
    "        acc_test = (1 - (mean_error / range_test)) * 100\n",
    "\n",
    "        acc_train = max(0.0, min(100.0, acc_train))\n",
    "        acc_test = max(0.0, min(100.0, acc_test))\n",
    "\n",
    "        print(f\"{name:>16}: {acc_test:6.2f}% (layout-based)   {acc_train:6.2f}% (train-scale)\")\n",
    "\n",
    "# === Circular Tracks ===\n",
    "def run_inference(data_folder, model_path):\n",
    "    print(\"Loading model and scalers...\")\n",
    "    model, scaler_x, scaler_y = load_model(model_path)\n",
    "    model.eval()\n",
    "\n",
    "    print(\"Loading unseen layouts from:\", data_folder)\n",
    "    layout_files = sorted(glob(os.path.join(data_folder, \"*.csv\")))\n",
    "    total_layouts = len(layout_files)\n",
    "    print(f\"Found {total_layouts} layout files.\\n\")\n",
    "\n",
    "    for layout_index, layout_path in enumerate(layout_files):\n",
    "        layout_name = os.path.basename(layout_path)\n",
    "        print(f\"[{layout_index + 1}/{total_layouts}] Predicting layout: {layout_name}\")\n",
    "\n",
    "        df = pd.read_csv(layout_path)\n",
    "        X = df[config[\"input_cols\"]].values\n",
    "        Y = df[config[\"output_cols\"]].values\n",
    "        X_scaled = scaler_x.transform(X)\n",
    "        n = len(X_scaled)\n",
    "        preds_real = np.zeros_like(Y)\n",
    "        trues_real = Y.copy()\n",
    "\n",
    "        for i in tqdm(range(n), desc=f\"[{layout_index + 1}/{total_layouts}]\"):\n",
    "            seq = np.array([X_scaled[(i + j) % n] for j in range(config[\"seq_len\"])])\n",
    "            X_tensor = torch.tensor(seq.reshape(1, config[\"seq_len\"], -1), dtype=torch.float32).to(config[\"device\"])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_scaled = model(X_tensor).cpu().squeeze().numpy()\n",
    "                pred_real = scaler_y.inverse_transform(pred_scaled.reshape(1, -1))[0]\n",
    "\n",
    "            target_idx = (i + config[\"seq_len\"]) % n\n",
    "            preds_real[target_idx] += pred_real\n",
    "\n",
    "        # === Plot X/Z comparison ===\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(trues_real[:, 0], trues_real[:, 2], label=\"True\", linewidth=2)\n",
    "        plt.plot(preds_real[:, 0], preds_real[:, 2], label=\"Predicted\", linewidth=2, linestyle=\"--\")\n",
    "        plt.title(f\"X vs Z: {layout_name}\")\n",
    "        plt.xlabel(\"X Coordinate\")\n",
    "        plt.ylabel(\"Z Coordinate\")\n",
    "        plt.axis(\"equal\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # === Accuracy ===\n",
    "        print_feature_accuracy(preds_real, trues_real, scaler_y, config[\"output_cols\"])\n",
    "\n",
    "        # === Spatial Error (X/Z only)\n",
    "        spatial_errors = np.linalg.norm(preds_real[:, [0, 2]] - trues_real[:, [0, 2]], axis=1)\n",
    "        mean_spatial_error = np.mean(spatial_errors)\n",
    "        max_spatial_error = np.max(spatial_errors)\n",
    "        print(f\"Mean X/Z spatial error: {mean_spatial_error:.2f}m, Max: {max_spatial_error:.2f}m\\n\")\n",
    "\n",
    "# === Non-Circular Tracks ===\n",
    "# def run_inference(data_folder, model_path):\n",
    "#     print(\"Loading model and scalers...\")\n",
    "#     model, scaler_x, scaler_y = load_model(model_path)\n",
    "#     model.eval()\n",
    "\n",
    "#     print(\"Loading unseen layouts from:\", data_folder)\n",
    "#     layout_files = sorted(glob(os.path.join(data_folder, \"*.csv\")))\n",
    "#     total_layouts = len(layout_files)\n",
    "#     print(f\"Found {total_layouts} layout files.\\n\")\n",
    "\n",
    "#     for layout_index, layout_path in enumerate(layout_files):\n",
    "#         layout_name = os.path.basename(layout_path)\n",
    "#         print(f\"[{layout_index + 1}/{total_layouts}] Predicting layout: {layout_name}\")\n",
    "\n",
    "#         # === Load layout data ===\n",
    "#         df = pd.read_csv(layout_path)\n",
    "#         X = df[config[\"input_cols\"]].values\n",
    "#         Y = df[config[\"output_cols\"]].values\n",
    "#         X_scaled = scaler_x.transform(X)\n",
    "#         n = len(X_scaled)\n",
    "#         seq_len = config[\"seq_len\"]\n",
    "\n",
    "#         preds_real = np.zeros_like(Y)\n",
    "#         trues_real = Y.copy()\n",
    "\n",
    "#         for i in tqdm(range(n), desc=f\"[{layout_index + 1}/{total_layouts}]\"):\n",
    "#             # Pad first `seq_len` frames with the first frame\n",
    "#             if i < seq_len:\n",
    "#                 pad = np.repeat(X_scaled[0:1], seq_len - i, axis=0)\n",
    "#                 seq = np.vstack([pad, X_scaled[0:i]])\n",
    "#             else:\n",
    "#                 seq = X_scaled[i - seq_len:i]\n",
    "\n",
    "#             X_tensor = torch.tensor(seq.reshape(1, seq_len, -1), dtype=torch.float32).to(config[\"device\"])\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 pred_scaled = model(X_tensor).cpu().squeeze().numpy()\n",
    "#                 pred_real = scaler_y.inverse_transform(pred_scaled.reshape(1, -1))[0]\n",
    "\n",
    "#             preds_real[i] = pred_real\n",
    "\n",
    "#         # === Plotting ===\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.plot(trues_real[:, 0], trues_real[:, 2], label=\"True\", linewidth=2)\n",
    "#         plt.plot(preds_real[:, 0], preds_real[:, 2], label=\"Predicted\", linewidth=2, linestyle=\"--\")\n",
    "#         plt.title(f\"X vs Z Trajectory: {layout_name}\")\n",
    "#         plt.xlabel(\"X Coordinate\")\n",
    "#         plt.ylabel(\"Z Coordinate\")\n",
    "#         plt.axis(\"equal\")\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#         # === Accuracy report ===\n",
    "#         print_feature_accuracy(preds_real, trues_real, scaler_y, config[\"output_cols\"])\n",
    "\n",
    "#         # === Spatial error metrics (just X/Z)\n",
    "#         spatial_errors = np.linalg.norm(preds_real[:, [0, 2]] - trues_real[:, [0, 2]], axis=1)\n",
    "#         mean_spatial_error = np.mean(spatial_errors)\n",
    "#         max_spatial_error = np.max(spatial_errors)\n",
    "#         print(f\"Mean X/Z spatial error: {mean_spatial_error:.2f}m, Max: {max_spatial_error:.2f}m\\n\")\n",
    "\n",
    "# === Run it ===\n",
    "run_inference(data_folder=\"./data/testing_layouts\", model_path=\"./models/testing_racing_line_lstm.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_inference(data_folder, model_path):\n",
    "#     print(\"Loading model and scalers...\")\n",
    "#     model, scaler_x, scaler_y = load_model(model_path)\n",
    "#     model.eval()\n",
    "\n",
    "#     print(\"Loading unseen layouts from:\", data_folder)\n",
    "#     layout_files = sorted(glob(os.path.join(data_folder, \"*.csv\")))\n",
    "#     total_layouts = len(layout_files)\n",
    "#     print(f\"Found {total_layouts} layout files.\\n\")\n",
    "\n",
    "#     for layout_index, layout_path in enumerate(layout_files):\n",
    "#         layout_name = os.path.basename(layout_path)\n",
    "#         print(f\"[{layout_index + 1}/{total_layouts}] Predicting layout: {layout_name}\")\n",
    "\n",
    "#         # === Load layout data ===\n",
    "#         df = pd.read_csv(layout_path)\n",
    "#         X = df[config[\"input_cols\"]].values\n",
    "#         Y = df[config[\"output_cols\"]].values\n",
    "#         X_scaled = scaler_x.transform(X)\n",
    "#         n = len(X_scaled)\n",
    "#         seq_len = config[\"seq_len\"]\n",
    "\n",
    "#         preds_real = np.zeros_like(Y)\n",
    "#         trues_real = Y.copy()\n",
    "\n",
    "#         for i in tqdm(range(n), desc=f\"[{layout_index + 1}/{total_layouts}]\"):\n",
    "#             # Pad first `seq_len` frames with the first frame\n",
    "#             if i < seq_len:\n",
    "#                 pad = np.repeat(X_scaled[0:1], seq_len - i, axis=0)\n",
    "#                 seq = np.vstack([pad, X_scaled[0:i]])\n",
    "#             else:\n",
    "#                 seq = X_scaled[i - seq_len:i]\n",
    "\n",
    "#             X_tensor = torch.tensor(seq.reshape(1, seq_len, -1), dtype=torch.float32).to(config[\"device\"])\n",
    "\n",
    "#             with torch.no_grad():\n",
    "#                 pred_scaled = model(X_tensor).cpu().squeeze().numpy()\n",
    "#                 pred_real = scaler_y.inverse_transform(pred_scaled.reshape(1, -1))[0]\n",
    "\n",
    "#             preds_real[i] = pred_real\n",
    "\n",
    "#         # === Plotting ===\n",
    "#         plt.figure(figsize=(12, 6))\n",
    "#         plt.plot(trues_real[:, 0], trues_real[:, 2], label=\"True\", linewidth=2)\n",
    "#         plt.plot(preds_real[:, 0], preds_real[:, 2], label=\"Predicted\", linewidth=2, linestyle=\"--\")\n",
    "#         plt.title(f\"X vs Z Trajectory: {layout_name}\")\n",
    "#         plt.xlabel(\"X Coordinate\")\n",
    "#         plt.ylabel(\"Z Coordinate\")\n",
    "#         plt.axis(\"equal\")\n",
    "#         plt.grid(True)\n",
    "#         plt.legend()\n",
    "#         plt.show()\n",
    "\n",
    "#         # === Accuracy report ===\n",
    "#         print_feature_accuracy(preds_real, trues_real, scaler_y, config[\"output_cols\"])\n",
    "\n",
    "#         # === Spatial error metrics (just X/Z)\n",
    "#         spatial_errors = np.linalg.norm(preds_real[:, [0, 2]] - trues_real[:, [0, 2]], axis=1)\n",
    "#         mean_spatial_error = np.mean(spatial_errors)\n",
    "#         max_spatial_error = np.max(spatial_errors)\n",
    "#         print(f\"Mean X/Z spatial error: {mean_spatial_error:.2f}m, Max: {max_spatial_error:.2f}m\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
